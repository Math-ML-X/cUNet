<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1200px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Continuous U-Net: Faster, Greater and Noiseless</title>
	<meta property="og:image" content="./resources/teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Continuous U-Net: Faster, Greater and Noiseless" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:32px">Continuous U-Net: Faster, Greater and Noiseless</span>
		<br>
		<br>
		<table align=center width=1100px>
			<table align=center width=1100px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px">Chun-Wun Cheng</a><sup>1,2∗</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px">Christina Runkel<sup>2∗</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px"><a href="https://lihaoliu-cambridge.github.io/">Lihao Liu</a><sup>2∗</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px"><a href="https://www.math.cuhk.edu.hk/~rchan/">Raymond H Chan</a><sup>1</sup></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:18px"><a href="https://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a><sup>2</sup></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:18px"><a href="https://angelicaiaviles.wordpress.com/">Angelica I. Aviles-Rivero</a><sup>2</sup></span>
						</center>
					</td>
				</tr>
			</table>			
			<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:21px"><sup>1</sup>City University of Hong Kong (CityU) &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  <sup>2</sup>University of Cambridge  </span><br/>
							<img width="550" src="./resources/logos.png" alt="affiliations">
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href='https://doi.org/10.48550/arXiv.2302.00626'>[Paper]</a></span>
						</center>
					</td>
					<!-- <td align=center width=190px>
						<center>
							<span style="font-size:24px"><a href=''>[Dataset](Coming Soon)</a></span><br>
						</center>
					</td> -->
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=560px>
					<center>
						<img class="round" style="width:950px" src="./resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=950px>
			<tr>
				<td>
					This is a website made for <a href='https://doi.org/10.48550/arXiv.2302.00626'>Continuous U-Net: Faster, Greater and Noiseless</a>. 
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=900px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Image segmentation is a fundamental task in image analysis and clinical practice. The current state-of-the-art techniques are based on U-shape type encoder-decoder networks with skip connections, called U-Net. Despite the powerful performance reported by existing U-Net type networks, they suffer from several major limitations. Issues include the hard coding of the receptive field size, compromising the performance and computational cost, as well as the fact that they do not account for inherent noise in the data. They have problems associated with discrete layers, and do not offer any theoretical underpinning. In this work we introduce continuous U-Net, a novel family of networks for image segmentation. Firstly, continuous U-Net is a continuous deep neural network that introduces new dynamic blocks modelled by second order ordinary differential equations. Secondly, we provide theoretical guarantees for our network demonstrating faster convergence, higher robustness and less sensitivity to noise. Thirdly, we derive qualitative measures to tailor-made segmentation tasks. We demonstrate, through extensive numerical and visual results, that our model outperforms existing U-Net blocks for several medical image segmentation benchmarking datasets.
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<center><h1>Network</h1></center>
	<table align=center width=850px>
		<tr>
			<td width=560px>
				<center>
					<img class="round" style="width:750px" src="./resources/network.png"/>
				</center>
			</td>
		</tr>
	</table>
</br>
	<table align=center width=950px>
		<tr>
			<td>
				Visual comparison of our continuous U-Net vs. UNet (and variants). The zoom-in views display the difference between discrete blocks in U-Net and our proposed dynamic blocks. 
			</td>
		</tr>
	</table>
</br>

	<hr>

	<center><h1>Properties</h1></center>
	<table align=center width=900px>
		<tr>
			<td align=center width=700px>
				<center>
					<td><img class="round" style="width:920px" src="./resources/feature.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=920px>
		<center>
			<tr>
				<td>
					Overview of properties of our continuous U-Net vs. existing U-type networks.
				</td>
			</tr>
		</center>
	</table>
	<br>
	<hr>
	<table align=center width=800px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href="https://doi.org/10.48550/arXiv.2302.00626"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt"><br>Chun-Wun Cheng*, Christina Runkel*, Lihao Liu*, Raymond H Chan, Carola-Bibiane Schonlieb, Angelica I Aviles-Rivero.<br>
				<b>Continuous U-Net: Faster, Greater and Noiseless</b><br>
				(hosted on <a href="https://doi.org/10.48550/arXiv.2302.00626">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=920px>
		<tr>
			<td width=420px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					CWC acknowledges support from Department of Mathematics, College of Science , CityU and HKASR reaching out award. AIAR acknowledges support from CMIH and CCIMI, University of Cambridge. CBS acknowledges support from the Philip Leverhulme Prize, the Royal Society Wolfson Fellowship, the EPSRC advanced career fellowship EP/V029428/1, EPSRC grants EP/S026045/1 and EP/T003553/1, EP/N014588/1, EP/T017961/1, the Wellcome Innovator Awards 215733/Z/19/Z and 221633/Z/20/Z, the European Union Horizon 2020 research and innovation programme under the Marie Skodowska-Curie grant agreement No. 777826 NoMADS, the Cantab Capital Institute for the Mathematics of Information and the Alan Turing Institute.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>
